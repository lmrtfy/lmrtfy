{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is the official documentation of the lmrtfy project! - GitHub Repository LMRTFY stands for Let Me Run That For You . Introduction \u00b6 lmrtfy is a tool to share your applications with others without dealing with the tedious things: Only minimal changes to your code by annotating your input and output variables Automatically generated API that can be shared with others Warning lmrtfy is currently in an early alpha phase. We try to minimize the things that will change in the future, but we cannot make any guarantees at the moment. Please keep that in mind while using the lmrtfy tools. Currently, the application itself runs on your computer and we provide a tightly controlled interface via our web API to start jobs that make use of the script running on your computer. Follow the quick start guide to get started! We also have a more comprehensive tutorial and examples that you might be interested in! Note If you encounter any obstacles while using our tool or while reading the documentation, please don't hesitate to contact us. Just create an issue on GitHub. Examples \u00b6 The examples are provided in the examples/ directory. They are work in progress . As lmrtfy matures, more and more examples will be added. If you miss an example for a specific use case, please let us know, and we will add one! Quickstart \u00b6 TL;DR \u00b6 intall with pip install lmrtfy login/sign up with lmrtfy login annotate your code's inputs with variable and its outputs with result in terminal 1 run lmrtfy deploy <script.py> --local (returns profile_id) in terminal 2 run lmrtfy submit <profile_id> <input.json> (returns job_id) in terminal 2 run lmrtfy fetch <job_id> <path> to get results Installation: \u00b6 $ pip install lmrtfy First login \u00b6 Login/sign up to receive access token: $ lmrtfy login . The token is saved in ~/.lmrtfy/auth/token but you should not need to manually open the token. Info Tokens are currently valid for 24 hours. After that you will be requested to login again. That also means that you cannot have scripts deployed more than 24 hours right now. This will change soon so that you can deploy scripts longer than that. Just run lmrtfy deploy <script> --local again after 24h and you are fine if you need longer running deployments right now.) Create code annotations \u00b6 Annotate the inputs and outputs of your script with variable and results and save it as script.py : # import the required things from lmrtfy from lmrtfy import variable , result # annotate an input time = variable ( 200. , name = \"time\" , min = 0 , max = 1000 , unit = \"s\" ) speed = result ( 9.81 * time , name = \"speed\" , min = 0 , max = 9810 , unit = \"m/s\" ) This calculates the velocity of an object in free fall after time seconds. Run python script.py to create the profile. This always works, even without access to lmrtfy. Deploy the script to accept jobs from the generated web API \u00b6 Run lmrtfy deploy script.py --local to generate the API and start the runner to listen to jobs for your script. You can find the profile id to submit a job in the logs: INFO Starting deployment of examples/velocity_from_gravity/calc_velocity.py WARNING Deploying locally. INFO Profile_id to be used for requests: 7ff68a0cfd8c61122cfdaf0a835c7cd1f94e7db9 Submit jobs with CLI \u00b6 Open a new terminal and submit a new job ( <profile_id> is the profile id you received during the deployment ( 7ff... in the example above)): $ lmrtfy submit <profile_id> <input.json> For the example above save the following in your input.json : { \"argument_values\" : { \"time\" : 200.0 }, \"argument_units\" : { \"time\" : \"s\" } } You will receive a job_id which you will need to fetch the results later on: INFO Job-id: 14584640 -778c-4f91-a288-03cffc2b9c7a Fetch results \u00b6 Get the results by calling $ lmrtfy fetch <job_id> <path> . Currently, the results will be saved in <path>/<job_id> as JSON files.","title":"LMRTFY"},{"location":"#introduction","text":"lmrtfy is a tool to share your applications with others without dealing with the tedious things: Only minimal changes to your code by annotating your input and output variables Automatically generated API that can be shared with others Warning lmrtfy is currently in an early alpha phase. We try to minimize the things that will change in the future, but we cannot make any guarantees at the moment. Please keep that in mind while using the lmrtfy tools. Currently, the application itself runs on your computer and we provide a tightly controlled interface via our web API to start jobs that make use of the script running on your computer. Follow the quick start guide to get started! We also have a more comprehensive tutorial and examples that you might be interested in! Note If you encounter any obstacles while using our tool or while reading the documentation, please don't hesitate to contact us. Just create an issue on GitHub.","title":"Introduction"},{"location":"#examples","text":"The examples are provided in the examples/ directory. They are work in progress . As lmrtfy matures, more and more examples will be added. If you miss an example for a specific use case, please let us know, and we will add one!","title":"Examples"},{"location":"#quickstart","text":"","title":"Quickstart"},{"location":"#tldr","text":"intall with pip install lmrtfy login/sign up with lmrtfy login annotate your code's inputs with variable and its outputs with result in terminal 1 run lmrtfy deploy <script.py> --local (returns profile_id) in terminal 2 run lmrtfy submit <profile_id> <input.json> (returns job_id) in terminal 2 run lmrtfy fetch <job_id> <path> to get results","title":"TL;DR"},{"location":"#installation","text":"$ pip install lmrtfy","title":"Installation:"},{"location":"#first-login","text":"Login/sign up to receive access token: $ lmrtfy login . The token is saved in ~/.lmrtfy/auth/token but you should not need to manually open the token. Info Tokens are currently valid for 24 hours. After that you will be requested to login again. That also means that you cannot have scripts deployed more than 24 hours right now. This will change soon so that you can deploy scripts longer than that. Just run lmrtfy deploy <script> --local again after 24h and you are fine if you need longer running deployments right now.)","title":"First login"},{"location":"#create-code-annotations","text":"Annotate the inputs and outputs of your script with variable and results and save it as script.py : # import the required things from lmrtfy from lmrtfy import variable , result # annotate an input time = variable ( 200. , name = \"time\" , min = 0 , max = 1000 , unit = \"s\" ) speed = result ( 9.81 * time , name = \"speed\" , min = 0 , max = 9810 , unit = \"m/s\" ) This calculates the velocity of an object in free fall after time seconds. Run python script.py to create the profile. This always works, even without access to lmrtfy.","title":"Create code annotations"},{"location":"#deploy-the-script-to-accept-jobs-from-the-generated-web-api","text":"Run lmrtfy deploy script.py --local to generate the API and start the runner to listen to jobs for your script. You can find the profile id to submit a job in the logs: INFO Starting deployment of examples/velocity_from_gravity/calc_velocity.py WARNING Deploying locally. INFO Profile_id to be used for requests: 7ff68a0cfd8c61122cfdaf0a835c7cd1f94e7db9","title":"Deploy the script to accept jobs from the generated web API"},{"location":"#submit-jobs-with-cli","text":"Open a new terminal and submit a new job ( <profile_id> is the profile id you received during the deployment ( 7ff... in the example above)): $ lmrtfy submit <profile_id> <input.json> For the example above save the following in your input.json : { \"argument_values\" : { \"time\" : 200.0 }, \"argument_units\" : { \"time\" : \"s\" } } You will receive a job_id which you will need to fetch the results later on: INFO Job-id: 14584640 -778c-4f91-a288-03cffc2b9c7a","title":"Submit jobs with CLI"},{"location":"#fetch-results","text":"Get the results by calling $ lmrtfy fetch <job_id> <path> . Currently, the results will be saved in <path>/<job_id> as JSON files.","title":"Fetch results"},{"location":"CHANGELOG/","text":"v0.0.6 - 08/sep/2022 \u00b6 changed input formats for json as follows: { \"profile_id\" : \"<profile_id>\" , \"job_parameters\" : { \"time\" : 200.0 }, \"parameter_units\" : { \"time\" : \"s\" } } to { \"argument_values\" : { \"time\" : 6.0 }, \"argument_units\" : { \"time\" : \"s\" } } modified readme to match docs added check if job_id is valid UUID v0.0.5 - 06/sep/2022 \u00b6 included version check changed listener to remove profile collisions v0.0.4 - 05/sep/2022 \u00b6 First release This creates the following commands: * lmrtfy login => get token * lmrtfy deploy <script.py> --local => get profile_id for deployed script profile * lmrtfy submit <profile_id> <input.json> => get job_id for submitted job * lmrtfy fetch <job_id> <path_to_save> => get results for finished job","title":"Changelog"},{"location":"CHANGELOG/#v006-08sep2022","text":"changed input formats for json as follows: { \"profile_id\" : \"<profile_id>\" , \"job_parameters\" : { \"time\" : 200.0 }, \"parameter_units\" : { \"time\" : \"s\" } } to { \"argument_values\" : { \"time\" : 6.0 }, \"argument_units\" : { \"time\" : \"s\" } } modified readme to match docs added check if job_id is valid UUID","title":"v0.0.6 - 08/sep/2022"},{"location":"CHANGELOG/#v005-06sep2022","text":"included version check changed listener to remove profile collisions","title":"v0.0.5 - 06/sep/2022"},{"location":"CHANGELOG/#v004-05sep2022","text":"First release This creates the following commands: * lmrtfy login => get token * lmrtfy deploy <script.py> --local => get profile_id for deployed script profile * lmrtfy submit <profile_id> <input.json> => get job_id for submitted job * lmrtfy fetch <job_id> <path_to_save> => get results for finished job","title":"v0.0.4 - 05/sep/2022"},{"location":"about/","text":"lmrtfy is a project that is currently work in progress. Things will change. If you have feature requests please let us know!","title":"About"},{"location":"examples/compound_interest/","text":"Example 3: Compound interest \u00b6 The third example calculates the compound interest \\(C\\) starting from a principal value \\(P\\) with annualt interest \\(I\\) after \\(N\\) years: \\[ C = P \\cdot (1 + I)^N - P \\] Very common formula in anything related to finance. Again, we start with the plain code, as you would implement it right away: # file: ci.py def compound_interest ( principal : float , annual_interest : float , years : int ): return principal * ( 1. + annual_interest / 100. ) ** years - principal if __name__ == \"__main__\" : principal = 10_000 interest = 6 years = 10 ci = compound_interest ( principal , interest , years ) print ( f \"Compound interest after { years } years: { ci } \" ) You can run this example with $ python ci.py and it should print 7908.47 . Which is the compound interest after 10 years if you started with 10000 units that grow by 6% each year. There are several problems with this solution: 1. You need to change the code to run it for other inputs 2. Units are unclear! principal is a currency, but that actually does not matter. The real problem is the interest . Is it decimal or in %? Annotate with lmrtfy \u00b6 Using lmrtfy, you would annotate the script as follows: # file: ci_lmrtfy_1.py from lmrtfy import variable , result def compound_interest ( principal : float , annual_interest : float , years : int ): return principal * ( 1. + annual_interest / 100. ) ** years - principal if __name__ == \"__main__\" : principal = variable ( 10_000 , name = \"principal\" , min = 0 ) interest = variable ( 6 , name = \"interest\" , min = 0 , max = 100 , unit = \"%\" ) years = variable ( 10 , name = \"years\" , min = 0 ) ci = compound_interest ( principal , interest , years ) ci = result ( ci , name = \"compound interest\" ) print ( f \"Compound interest after { years } years: { ci } \" ) Now, we run python ci_lmrtfy_1.py to generate the profile. Warning The type annotation are not enforced when run locally. LMRTFY checks the types and units only if jobs are submitted through its API. This guarantees that you can run your code without our service. After creating the profile we can easily deploy with $ lmrtfy deploy ci_lmrtfy_1.py --local The output should be similar to this: INFO Profile_id to be used for requests: <profile_id> The <profile_id> is important to submit jobs. Submit a job \u00b6 To submit a job you are currently required to save the input parameters as JSON (e.g. input.json ): { \"argument_values\" : { \"annual_interest\" : 6.0 , \"principal\" : 5000.0 , \"years\" : 10 }, \"argument_units\" : { \"annual_interest\" : \"%\" } } Now, we have everything that is needed to start a job: $ lmrtfy submit <profile_id> input.json The job id for this job is printed to the terminal: INFO Job-id: <job_id> We need the <job_id> later to fetch the results from the computation. Alternative \u00b6 A more compact but working alternative is to create the result as follows: from lmrtfy import variable , result def compound_interest ( principal : float , annual_interest : float , years : int ): return principal * ( 1. + annual_interest / 100. ) ** years - principal if __name__ == \"__main__\" : ci = result ( compound_interest ( principal = variable ( 10000. , name = \"principal\" , min = 0 ), annual_interest = variable ( 6 , name = \"annual_interest\" , min = 0 , max = 100 , unit = \"%\" ), years = variable ( 10 , name = \"years\" , min = 0 ) ), name = \"compound_interest\" ) print ( ci ) It's not necessarily prettier to look at, but also works!","title":"Compound Interest"},{"location":"examples/compound_interest/#example-3-compound-interest","text":"The third example calculates the compound interest \\(C\\) starting from a principal value \\(P\\) with annualt interest \\(I\\) after \\(N\\) years: \\[ C = P \\cdot (1 + I)^N - P \\] Very common formula in anything related to finance. Again, we start with the plain code, as you would implement it right away: # file: ci.py def compound_interest ( principal : float , annual_interest : float , years : int ): return principal * ( 1. + annual_interest / 100. ) ** years - principal if __name__ == \"__main__\" : principal = 10_000 interest = 6 years = 10 ci = compound_interest ( principal , interest , years ) print ( f \"Compound interest after { years } years: { ci } \" ) You can run this example with $ python ci.py and it should print 7908.47 . Which is the compound interest after 10 years if you started with 10000 units that grow by 6% each year. There are several problems with this solution: 1. You need to change the code to run it for other inputs 2. Units are unclear! principal is a currency, but that actually does not matter. The real problem is the interest . Is it decimal or in %?","title":"Example 3: Compound interest"},{"location":"examples/compound_interest/#annotate-with-lmrtfy","text":"Using lmrtfy, you would annotate the script as follows: # file: ci_lmrtfy_1.py from lmrtfy import variable , result def compound_interest ( principal : float , annual_interest : float , years : int ): return principal * ( 1. + annual_interest / 100. ) ** years - principal if __name__ == \"__main__\" : principal = variable ( 10_000 , name = \"principal\" , min = 0 ) interest = variable ( 6 , name = \"interest\" , min = 0 , max = 100 , unit = \"%\" ) years = variable ( 10 , name = \"years\" , min = 0 ) ci = compound_interest ( principal , interest , years ) ci = result ( ci , name = \"compound interest\" ) print ( f \"Compound interest after { years } years: { ci } \" ) Now, we run python ci_lmrtfy_1.py to generate the profile. Warning The type annotation are not enforced when run locally. LMRTFY checks the types and units only if jobs are submitted through its API. This guarantees that you can run your code without our service. After creating the profile we can easily deploy with $ lmrtfy deploy ci_lmrtfy_1.py --local The output should be similar to this: INFO Profile_id to be used for requests: <profile_id> The <profile_id> is important to submit jobs.","title":"Annotate with lmrtfy"},{"location":"examples/compound_interest/#submit-a-job","text":"To submit a job you are currently required to save the input parameters as JSON (e.g. input.json ): { \"argument_values\" : { \"annual_interest\" : 6.0 , \"principal\" : 5000.0 , \"years\" : 10 }, \"argument_units\" : { \"annual_interest\" : \"%\" } } Now, we have everything that is needed to start a job: $ lmrtfy submit <profile_id> input.json The job id for this job is printed to the terminal: INFO Job-id: <job_id> We need the <job_id> later to fetch the results from the computation.","title":"Submit a job"},{"location":"examples/compound_interest/#alternative","text":"A more compact but working alternative is to create the result as follows: from lmrtfy import variable , result def compound_interest ( principal : float , annual_interest : float , years : int ): return principal * ( 1. + annual_interest / 100. ) ** years - principal if __name__ == \"__main__\" : ci = result ( compound_interest ( principal = variable ( 10000. , name = \"principal\" , min = 0 ), annual_interest = variable ( 6 , name = \"annual_interest\" , min = 0 , max = 100 , unit = \"%\" ), years = variable ( 10 , name = \"years\" , min = 0 ) ), name = \"compound_interest\" ) print ( ci ) It's not necessarily prettier to look at, but also works!","title":"Alternative"},{"location":"examples/free_fall/","text":"Example 2: Velocity due to gravtity in free fall \u00b6 The second example calculates the velocity of an object falling from the sky (without air resistance). The standard gravity on earth is 9.81 m*s^(-2). Multiplicated by the fall time, we will get the velocity of the object after that time. If you like equations more, you might recognize these from your physics class: $$ v = g \\cdot t $$ In regular python code that you run locally it would look like this: standard_gravity = 9.81 time = 200. velocity = standard_gravity * time print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) Now we want to be able to share that functionality via the lmrtfy web API. All we have to do is decide which variables are considered to be an input and a result of the computation: from lmrtfy import variable , result standard_gravity = 9.81 time = variable ( 200. , name = \"time\" , min = 0 , max = 1000 , unit = \"s\" ) velocity = result ( standard_gravity * time , name = \"velocity\" , min = 0 , max = 9810 , unit = \"m/s\" ) print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) Now run $ python examples/velocity_from_gravity/calc_velocity.py to generate the required profile. This way you can also check if your code is actually working the way you expect it. To deploy, you simply run $ lmrtfy deploy examples/velocity_from_gravity/calc_velocity.py --local . Do not stop that process, because than you will not be able to submit a job. Open a new terminal in the same directory and run $ lmrtfy submit <profile_id> . The profile_id has been printed in the lmrtfy deploy step. This does not work right out of the box, because you need to specify a JSON file that contains the input parameters for your job. A template for that JSON should have been printed in the CLI. Create such a JSON file and name it input.json and put values of the correct type into the values (no type conversion is happening in the API, so if float is required, you cannot input an int ). Now run $ lmrtfy submit <profile_id> input.json . You will receive a job_id which we will shortly need to fetch the results after they are computed. After your job has run, you can get the results by running $ lmrtfy fetch <job_id> <path to store results> . The results are downloaded and stored inside the specified path within a directory that has the job_id as its name.","title":"Free Fall"},{"location":"examples/free_fall/#example-2-velocity-due-to-gravtity-in-free-fall","text":"The second example calculates the velocity of an object falling from the sky (without air resistance). The standard gravity on earth is 9.81 m*s^(-2). Multiplicated by the fall time, we will get the velocity of the object after that time. If you like equations more, you might recognize these from your physics class: $$ v = g \\cdot t $$ In regular python code that you run locally it would look like this: standard_gravity = 9.81 time = 200. velocity = standard_gravity * time print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) Now we want to be able to share that functionality via the lmrtfy web API. All we have to do is decide which variables are considered to be an input and a result of the computation: from lmrtfy import variable , result standard_gravity = 9.81 time = variable ( 200. , name = \"time\" , min = 0 , max = 1000 , unit = \"s\" ) velocity = result ( standard_gravity * time , name = \"velocity\" , min = 0 , max = 9810 , unit = \"m/s\" ) print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) Now run $ python examples/velocity_from_gravity/calc_velocity.py to generate the required profile. This way you can also check if your code is actually working the way you expect it. To deploy, you simply run $ lmrtfy deploy examples/velocity_from_gravity/calc_velocity.py --local . Do not stop that process, because than you will not be able to submit a job. Open a new terminal in the same directory and run $ lmrtfy submit <profile_id> . The profile_id has been printed in the lmrtfy deploy step. This does not work right out of the box, because you need to specify a JSON file that contains the input parameters for your job. A template for that JSON should have been printed in the CLI. Create such a JSON file and name it input.json and put values of the correct type into the values (no type conversion is happening in the API, so if float is required, you cannot input an int ). Now run $ lmrtfy submit <profile_id> input.json . You will receive a job_id which we will shortly need to fetch the results after they are computed. After your job has run, you can get the results by running $ lmrtfy fetch <job_id> <path to store results> . The results are downloaded and stored inside the specified path within a directory that has the job_id as its name.","title":"Example 2: Velocity due to gravtity in free fall"},{"location":"examples/starting_example/","text":"Example 1: Simple annotation \u00b6 This is a simple example to showcase the general usage of lmrtfy. It can be found in examples/example1/example1.py . The two core concepts are the variable and result functions which annotate the inputs and outputs of the script. They are needed to create the profile which is used to create the API. import numpy as np from lmrtfy import variable , result # 1 x = variable ( 5 , name = \"x\" , min = 1 , max = 10 ) # 2 y = variable ( np . linspace ( 0. , 1. , 101 , dtype = np . float64 ), name = \"y\" , min =- 1. , max = 11. , unit = \"m\" ) # 3 z = variable ( \"abc\" , name = \"z\" ) z1 = variable ([ \"abc\" , \"def\" ], name = \"z1\" ) # 4 z2 = variable ([ \"abc\" , 1 , 1.1 ], name = \"z2\" ) z3 = variable ({ 'a' : \"abc\" , 'b' : 1 }, name = \"z3\" ) a = result ( x * y , name = \"a\" ) # 5 b = result ( x * z , name = \"b\" ) The functions need to be imported from the lmrtfy library The variable x has the local value 5 and can be between 1 and 10. You can have numpy arrays as inputs Lists and dictionaries work, too! Results are similar to variables. They have a name and an expression that they will become.","title":"Starting Example"},{"location":"examples/starting_example/#example-1-simple-annotation","text":"This is a simple example to showcase the general usage of lmrtfy. It can be found in examples/example1/example1.py . The two core concepts are the variable and result functions which annotate the inputs and outputs of the script. They are needed to create the profile which is used to create the API. import numpy as np from lmrtfy import variable , result # 1 x = variable ( 5 , name = \"x\" , min = 1 , max = 10 ) # 2 y = variable ( np . linspace ( 0. , 1. , 101 , dtype = np . float64 ), name = \"y\" , min =- 1. , max = 11. , unit = \"m\" ) # 3 z = variable ( \"abc\" , name = \"z\" ) z1 = variable ([ \"abc\" , \"def\" ], name = \"z1\" ) # 4 z2 = variable ([ \"abc\" , 1 , 1.1 ], name = \"z2\" ) z3 = variable ({ 'a' : \"abc\" , 'b' : 1 }, name = \"z3\" ) a = result ( x * y , name = \"a\" ) # 5 b = result ( x * z , name = \"b\" ) The functions need to be imported from the lmrtfy library The variable x has the local value 5 and can be between 1 and 10. You can have numpy arrays as inputs Lists and dictionaries work, too! Results are similar to variables. They have a name and an expression that they will become.","title":"Example 1: Simple annotation"},{"location":"tutorial/annotation/","text":"Annotate your script \u00b6 The annotation of your script tells the lmrtfy tool which python variables are considered inputs and outputs, which is done via the variable and results functions. This step is important, because lmrtfy traces the calls to variable and result to create a profile for the code. This profile includes the inputs and outputs as well as the additional meta information ( min , max , unit , and possibly more in the future). Let's assume that you have create a script to calculate the velocity of an object after a certain time: # file: free_fall.py standard_gravity = 9.81 time = 200. velocity = standard_gravity * time print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) Now, if you want to recalculate for a different time, you would edit the script and run it again. While this might work for a small script like this, this becomes tedious if you have different input variables and want others to use your script easily, too. Let's change the script in such a way that lmrtfy can create a profile which can be used to deploy the function and make it available to other users: # file: free_fall_lmrtfy.py # import the required things from lmrtfy from lmrtfy import variable , result standard_gravity = 9.81 # annotate an input time = variable ( 200. , name = \"time\" , min = 0 , max = 1000 , unit = \"s\" ) # annotate an output velocity = result ( 9.81 * time , name = \"velocity\" , min = 0 , max = 9810 , unit = \"m\" ) print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) If you run python free_fall_lmrtfy.py you get the exact same result as before. During the run, lmrtfy created the profile for free_fall_lmrtfy.py which will be needed to deploy the function. Create the annotation profile \u00b6 It is required to run your script at least once with the regular python interpreter to create the annotation profile which will be used to generate the API. $ python <script.py> The profile is currently saved under ~/.lmrtfy/profiles which will change in the future to respect XDG directory specifications. Focus: variable and result \u00b6 These functions are transparent. That means the assignment a = variable(5, name=\"a\") assigns a the value 5 . This way you can run the script simply with your local python interpreter if lmrtfy is installed in the environment. variable and result do not have any external dependency (e.g. API calls) The functions signatures are as follows. Only the first two arguments are required. Ideally, the name argument should match the name of the variable you assign to, although that is not necessary. It's considered to be a best practice, because it reduces possible errors and fosters a more intuitive understanding of the code. # variable signature: variable ( value : supported_object_type , name : str , min = None , max = None , unit : str = None ) -> supported_object_type # result signature: result ( value : supported_object_type , name : str , min = None , max = None , unit : str = None ) -> supported_object_type The value argument specifies the default argument for the variable and has to be one of the supported types: int, float, complex, bool, np.ndarray, list, dict . name declares the name of the variable that will be used for the API generation. A sensible choice is the same name as the variable's name in the code itself. min and max can be used to specify boundaries for the input and output values in case they are numeric. This might come in handy if the code only works for certain input parameter ranges. If the inputs are outside the specified range the job will be rejected by the generated API. unit is a str that declares the unit of the variable/result. This is especially useful in scientific calculations where units are often not standardized and unclear.","title":"Annotate your script"},{"location":"tutorial/annotation/#annotate-your-script","text":"The annotation of your script tells the lmrtfy tool which python variables are considered inputs and outputs, which is done via the variable and results functions. This step is important, because lmrtfy traces the calls to variable and result to create a profile for the code. This profile includes the inputs and outputs as well as the additional meta information ( min , max , unit , and possibly more in the future). Let's assume that you have create a script to calculate the velocity of an object after a certain time: # file: free_fall.py standard_gravity = 9.81 time = 200. velocity = standard_gravity * time print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) Now, if you want to recalculate for a different time, you would edit the script and run it again. While this might work for a small script like this, this becomes tedious if you have different input variables and want others to use your script easily, too. Let's change the script in such a way that lmrtfy can create a profile which can be used to deploy the function and make it available to other users: # file: free_fall_lmrtfy.py # import the required things from lmrtfy from lmrtfy import variable , result standard_gravity = 9.81 # annotate an input time = variable ( 200. , name = \"time\" , min = 0 , max = 1000 , unit = \"s\" ) # annotate an output velocity = result ( 9.81 * time , name = \"velocity\" , min = 0 , max = 9810 , unit = \"m\" ) print ( f \"Velocity after { time } seconds is { velocity } m/s.\" ) If you run python free_fall_lmrtfy.py you get the exact same result as before. During the run, lmrtfy created the profile for free_fall_lmrtfy.py which will be needed to deploy the function.","title":"Annotate your script"},{"location":"tutorial/annotation/#create-the-annotation-profile","text":"It is required to run your script at least once with the regular python interpreter to create the annotation profile which will be used to generate the API. $ python <script.py> The profile is currently saved under ~/.lmrtfy/profiles which will change in the future to respect XDG directory specifications.","title":"Create the annotation profile"},{"location":"tutorial/annotation/#focus-variable-and-result","text":"These functions are transparent. That means the assignment a = variable(5, name=\"a\") assigns a the value 5 . This way you can run the script simply with your local python interpreter if lmrtfy is installed in the environment. variable and result do not have any external dependency (e.g. API calls) The functions signatures are as follows. Only the first two arguments are required. Ideally, the name argument should match the name of the variable you assign to, although that is not necessary. It's considered to be a best practice, because it reduces possible errors and fosters a more intuitive understanding of the code. # variable signature: variable ( value : supported_object_type , name : str , min = None , max = None , unit : str = None ) -> supported_object_type # result signature: result ( value : supported_object_type , name : str , min = None , max = None , unit : str = None ) -> supported_object_type The value argument specifies the default argument for the variable and has to be one of the supported types: int, float, complex, bool, np.ndarray, list, dict . name declares the name of the variable that will be used for the API generation. A sensible choice is the same name as the variable's name in the code itself. min and max can be used to specify boundaries for the input and output values in case they are numeric. This might come in handy if the code only works for certain input parameter ranges. If the inputs are outside the specified range the job will be rejected by the generated API. unit is a str that declares the unit of the variable/result. This is especially useful in scientific calculations where units are often not standardized and unclear.","title":"Focus: variable and result"},{"location":"tutorial/deployment/","text":"Deploy the function (local runner) \u00b6 Now you can deploy the function and make it available via the lmrtfy API. This is simply done by $ lmrtfy deploy <path_to_script.py> --local The --local flag means that the script will run locally on your computer and waits for jobs from the outside. The lmrtfy API only allows job submissions that fit your deployed annotation profile. In the future you will be able to deploy directly to the cloud. Then, you do not have to host the runner yourself. The current workaround would be to use lmrtfy on a server or inside a docker container which can be hosted in the cloud. When a job is submitted the types of the job's input parameters are checked by the lmrtfy API. Futhermore they are also checked for their bounds and their units. This way, only jobs that can be run successfully with the script belonging to the deployed profile. Warning Don't change the script after you have deployed it. The current advice would be to copy and rename the script before deployment. In later versions, this will be taken care of by the lmrtfy tool","title":"Deploy your script/function"},{"location":"tutorial/deployment/#deploy-the-function-local-runner","text":"Now you can deploy the function and make it available via the lmrtfy API. This is simply done by $ lmrtfy deploy <path_to_script.py> --local The --local flag means that the script will run locally on your computer and waits for jobs from the outside. The lmrtfy API only allows job submissions that fit your deployed annotation profile. In the future you will be able to deploy directly to the cloud. Then, you do not have to host the runner yourself. The current workaround would be to use lmrtfy on a server or inside a docker container which can be hosted in the cloud. When a job is submitted the types of the job's input parameters are checked by the lmrtfy API. Futhermore they are also checked for their bounds and their units. This way, only jobs that can be run successfully with the script belonging to the deployed profile. Warning Don't change the script after you have deployed it. The current advice would be to copy and rename the script before deployment. In later versions, this will be taken care of by the lmrtfy tool","title":"Deploy the function (local runner)"},{"location":"tutorial/fetch_results/","text":"Get results \u00b6 lmrtfy also provides a way to download the results of the computation. All you need is the <job_id> that you received when you submitted the job. Then, you simply run $ lmrtfy fetch <job_id> <save_path> The results will be saved in <save_path>/<job_id>/.. . Each result is currently saved as a JSON file with the following format: { \"<var_name>\" : < value > } Each variable has its own file. Warning This will very likely change in the future to be more ergonomic.","title":"Get results"},{"location":"tutorial/fetch_results/#get-results","text":"lmrtfy also provides a way to download the results of the computation. All you need is the <job_id> that you received when you submitted the job. Then, you simply run $ lmrtfy fetch <job_id> <save_path> The results will be saved in <save_path>/<job_id>/.. . Each result is currently saved as a JSON file with the following format: { \"<var_name>\" : < value > } Each variable has its own file. Warning This will very likely change in the future to be more ergonomic.","title":"Get results"},{"location":"tutorial/installation/","text":"There are two ways to install the lmrtfy tools. We recommend the usage of virtual environments at the moment due to the frequent updates and changes of lmrtfy. Install with pip (recommended) \u00b6 Use pip to install from PyPI: $ pip install lmrtfy This way you will always have the most recent release of the lmrtfy tools. Install from source \u00b6 You can also install from git which is the best way to use the nightly features. Clone the git repository and install manually: $ git clone --branch main https://github.com/lmrtfy/lmrtfy.git $ cd lmrtfy $ pip install . The main branch is the release branch and should always work with the lmrtfy API. Alternatively, you can use the develop branch. This should be the most up-to-date branch in the repository, but things might break. So be careful while using the develop branch.","title":"Installation"},{"location":"tutorial/installation/#install-with-pip-recommended","text":"Use pip to install from PyPI: $ pip install lmrtfy This way you will always have the most recent release of the lmrtfy tools.","title":"Install with pip (recommended)"},{"location":"tutorial/installation/#install-from-source","text":"You can also install from git which is the best way to use the nightly features. Clone the git repository and install manually: $ git clone --branch main https://github.com/lmrtfy/lmrtfy.git $ cd lmrtfy $ pip install . The main branch is the release branch and should always work with the lmrtfy API. Alternatively, you can use the develop branch. This should be the most up-to-date branch in the repository, but things might break. So be careful while using the develop branch.","title":"Install from source"},{"location":"tutorial/submission/","text":"Submit a job \u00b6 The lmrtfy tool also provides a way to submit jobs with the lmrtfy CLI tool. All you need for this is a profile_id which is provided by you during the deployment and a JSON file that contains the input parameters. Info Later on, you will be able to see available profile_id on our web frontend For the listing above, the JSON file would look like this: { \"argument_values\" : { \"time\" : 200.0 }, \"argument_units\" : { \"time\" : \"s\" } } argument_values and argument_units contain a key-value pair each for each of the inputs in the annotation profile. The types need to match exactly. No implicit type casting in performed during the submission. The unit also has to match exactly. Save the JSON file es input.json and run: $ lmrtfy deploy <profile_id> input.json --local Info Later on, we might perform automatic conversion in case of a unit mismatch, e.g. if the profile requires s (as in seconds) but the input is given as h (as in hours). There will be an option to enable/disable the function. If you have any opinions about that, please let us know When you submit your job you will receive a job_id which is needed to fetch the results as you will see in the next part of this guide.","title":"Submit a job"},{"location":"tutorial/submission/#submit-a-job","text":"The lmrtfy tool also provides a way to submit jobs with the lmrtfy CLI tool. All you need for this is a profile_id which is provided by you during the deployment and a JSON file that contains the input parameters. Info Later on, you will be able to see available profile_id on our web frontend For the listing above, the JSON file would look like this: { \"argument_values\" : { \"time\" : 200.0 }, \"argument_units\" : { \"time\" : \"s\" } } argument_values and argument_units contain a key-value pair each for each of the inputs in the annotation profile. The types need to match exactly. No implicit type casting in performed during the submission. The unit also has to match exactly. Save the JSON file es input.json and run: $ lmrtfy deploy <profile_id> input.json --local Info Later on, we might perform automatic conversion in case of a unit mismatch, e.g. if the profile requires s (as in seconds) but the input is given as h (as in hours). There will be an option to enable/disable the function. If you have any opinions about that, please let us know When you submit your job you will receive a job_id which is needed to fetch the results as you will see in the next part of this guide.","title":"Submit a job"}]}